

# ISLR学习笔记第二章



Tags :  统计学习

---

[TOC]

## 1.统计学习相关概念

统计学习主要是要估计出函数$f$。

### 	1.1 估计函数$f$的目的

我们估计出函数$f$，主要有两个目的一是预测，二是推断。

对于预测来说，我们目标是减少reducible error,使我们预测准确性提升，而unreducible error 对于我们预测的精度给出了一个无法预测的精度
$$
\begin{align}
E(Y-\hat{Y})^2&=E[f(x)-\hat{f}(x)-\epsilon]^2\\
&=[f(x)-\hat{f}(x)]^2+var(\epsilon)
\end{align}
$$

对于推断来说，我们更加注重因变量与自变量是否相关，或者两者是否具有因果效应，因此我们通常会采用线性模型。最后我们要根据我们的不同目的来选择适应的模型，当然有些模型既可以进行预测也可以进行拟合

### 1.2 估计函数$f$的方法

我们对于函数$f$的估计通常有两种形式，一种是参数估计，一种是非参数估计。参数估计的主要步骤包括两步，首先是对具体的函数进行假定，接着就是通过具体的函数形式通过训练组来对参数进行估计。这样其实大大降低了我们估计$f$的难度，仅仅转化为为对于特定参数的估计。但是它也存在着几个问题，首先就是对于函数形式是否被正确假定，如果假设的函数形式与我们的真实的函数形式相差过大的话，就会导致我们预测能力较差，为了解决上面这个问题，我们会采取较为复杂参数较多的模型。这样的话它会引致过拟合的问题，这样的话会把一些噪音以及随机性的东西考虑进我们的模型，使得模型的可用性较低。

另外是非参数估计，它可能地接近数据点，而又不会过于粗糙或波动大。它的优点在于并没有一味的去寻找$f$的真正的形式，它避免做出这样的假设，它们有可能准确地拟合f的可能形状的更广泛范围。任何参数方法都可能使用于估计f的函数形式与真实f完全不同，在这种情况下，所得模型将无法很好地拟合数据。相比之下，非参数方法完全避免了这种对f的形式做任何假设。但是非参数方法确实有一个主要的缺点：为了获得f的准确估计，由于它们不能将估计f的问题减少到少量参数，因此需要大量的观测值（远远超过参数方法通常所需的观测值）。

### 1.3 模型的预测精度和可解释性间的trade-off

![the tradeoff between flexibility and interepretability](D:\www\R5ea8dcb28a080441acb5e6625e99ad70.png)

### 1.4  监督学习 VS 无监督学习

简而言之监督学习的每一个输入都有对于的$y$，我们的模型为了预测的话是为了更好的接近$y$，为了推断的话也是更好地理解和$y$与我们的输入之间的关系。但是对于非监督学习我们并没有这个$y$，我们是根据给出输入的特征来对我们的输入进行分类，常见的就有我们的Cluster。当然也存在半监督学习，也就是有部分数据给了$y$,但是有一部分并没有，这并不在我们这本书的一个讨论范围。

### 1.5 回归问题 VS 分类问题

我们把统计学习问题可以分为回归和分类问题，回归问题就是我们的因变量是定量的还是定性的，如果是定量的话就是回归问题，定性的则是分类问题，但是这也只是一种通常的说法。如果分类问题估计类的概率，也可以认为它是一种回归方法，这个划分并不是绝对的。

## 2. 评价统计模型准确性

### 2.1 衡量拟合效果

在回归问题种我们通常使用MSE(均方误差)来对模型的拟合效果进行衡量，通常我们得到的是我们训练集的MSE，但是我们对于训练集上的MSE并不是很关心，我们更关心在测试集上的MSE。但是我们对模型的训练是基于训练集，我们通常会选择训练的MSE最小的，但是并没有证据表明我们训练集上MSE最小就会使得我们的测试集上的MSE最小，可能我们会遇上各种情况，下图是关于自由度可以看作模型的复杂度和我们均方误差之间的一般关系，我们可以发现随着自由度的上升我们的训练集上的MSE会逐渐下降，但我们测试集上的MSE却呈现一个U形趋势

![Snipaste_2021-05-12_23-30-47](D:\www\Snipaste_2021-05-12_23-30-47.png)



在显示中，通常可以相对轻松地计算出训练MSE，但是估计测试MSE的难度要大得多，因为通常没有可用的测试数据。而且在数据集之间，具有最小测试MSE的模型所对应的灵活性级别可能会有很大差异。面对没有测试集的情况，一种重要的方法是交叉验证，这是一种使用训练数据估计测试MSE的交叉方法。

###  2.2  Bias-Variance Trade-Of

测试集上的MSE却呈现一个U形趋势其实是由于两种互斥的性质也就是我们的bias和variance，variance指的是如果我们使用不同的训练数据集估算时$\hat{f}$的变化量，bias指的是我们使用模型逼近真实问题是引入的误差。其实两者都有它准确的数学定义，从数学我们可以证明：
$$
E(y_0-\hat{f}(x_0))^2=Var(\hat{f}(x_o))+[Bias(\hat{f}(x_0))]+Var(\epsilon)
$$
$E(y_0-\hat{f}(x_0))^2$是我们测试集上的MSE，由于我们要最小化我们测试集上的MSE，所以我们需要寻找一个模型使得我们的bias和variance都很小，但是通常，随着我们使用更灵活的方法，variance将增加而bias将减小。它们之间的关系可以被下面的图描述

![](D:\www\Snipaste_2021-05-13_00-17-36.png)

## 3. 实例：分类问题

我们前面的很多例子概念都是基于回归问题，现在我们把目光转回回归问题，由于$y$不再是连续的数值型，有一些概念需要做出一定的调整。我们衡量分类问题模型的准确度常常使用错误率这一指标
$$
\dfrac{1}{n}\sum_{i=1}^NI(y_i\ne\hat{y_i})
$$


### 贝叶斯分类器

我们可以通过一个简单的方法是我们测试集的误差最小



### KNN



## 4.R的入门

在这里不再赘述，可以参看《R for data science》，或者比较熟悉python语言后面的章节可以参见GitHub上的[python版本](https://github.com/JWarmenhoven/ISLR-python)。





[1]:An Introduction to Statistical Learning











